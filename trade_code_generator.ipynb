{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trading Code Generation"
      ],
      "metadata": {
        "id": "ZIVKgw4a6JWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**: Use LLM to write trading code to buy and sell equities in a simulated (Paper trading) environment, based on an API."
      ],
      "metadata": {
        "id": "-4s5m-Ar6QrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumptions:\n",
        "\n",
        "\n",
        "*   `tickers` is a list of stock tickers (strings), representing available stocks to trade.\n",
        "*   `prices` is a dictionary where: (1) The key is a stock ticker (string). AND (2) The value is a list of historical prices (floats), ordered with the most recent price first.\n",
        "*   `Trade` is a class that represents a trading decision. It takes two arguments: (1) `ticker`: A string representing the stock ticker. AND (2) `quantity`: An integer representing the number of shares to buy (positive) or sell/short (negative).\n",
        "\n"
      ],
      "metadata": {
        "id": "doPirMDjD-oO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "YzPNGrf0608R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio\n",
        "!pip -q install huggingface_hub\n",
        "!pip -q install transformers\n",
        "!pip -q install anthropic"
      ],
      "metadata": {
        "id": "r9WqqSb77IqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gradio"
      ],
      "metadata": {
        "id": "O_1wHVkaTsW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wUSbozzNZnH"
      },
      "outputs": [],
      "source": [
        "from alpaca.data.requests import StockLatestTradeRequest\n",
        "import gradio as gr\n",
        "from huggingface_hub import login, InferenceClient\n",
        "from transformers import AutoTokenizer\n",
        "from google.colab import userdata\n",
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up models and API Keys"
      ],
      "metadata": {
        "id": "c7maLCzS89RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anthropic_api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "jDXO14nx8UWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open-source LLM Models\n",
        "code_qwen = \"Qwen/CodeQwen1.5-7B-Chat\"\n",
        "CODE_QWEN_URL = \"your-end-point\""
      ],
      "metadata": {
        "id": "-_NNQnEg9P8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Closed-source LLM Models\n",
        "CLAUDE_MODEL = \"claude-sonnet-4-20250514\""
      ],
      "metadata": {
        "id": "IVdsJFtt-Iq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build model"
      ],
      "metadata": {
        "id": "G5kxd7TwB1zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 2000"
      ],
      "metadata": {
        "id": "xc0bU4VIH2Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an advanced code generation assistant capable of creating high-quality Python code for financial trading systems.\n",
        "Your task is to generate Python functions that simulate trading decisions based on the following API:\n",
        "\n",
        "API DETAILS:\n",
        "1. tickers: A list of stock tickers (strings) representing available stocks.\n",
        "2. prices: A dictionary where the key is a stock ticker (string) and the value is a list of historical prices (floats). The list is ordered with the most recent price first.\n",
        "3. Trade: A class used to represent trading actions.\n",
        "   - `Trade(ticker, quantity)` creates a trade object:\n",
        "     - Positive `quantity` (e.g., `100`) represents buying shares.\n",
        "     - Negative `quantity` (e.g., `-50`) represents selling/shorting shares.\n",
        "\n",
        "Example Function:\n",
        "# tickers is a list of stock tickers (strings)\n",
        "import tickers\n",
        "\n",
        "# prices is a dict; the key is a ticker and the value is a list of historic prices, today first\n",
        "import prices\n",
        "\n",
        "# Trade represents a decision to buy or sell a quantity of a ticker\n",
        "# Trade(\"IBM\", 100) for a trade object representing purchasing 100 shares of IBM stock\n",
        "# Trade(\"IBM\", -50) for a trade object representing selling or shorting 50 shares of IBM stock\n",
        "import Trade\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def trade1():\n",
        "    # Buy top performing stock in the last 5 days\n",
        "    avg_prices = {ticker: np.mean(prices[ticker][:5]) for ticker in tickers}\n",
        "    best_ticker = max(avg_prices, key=avg_prices.get)\n",
        "    trade = Trade(best_ticker, 100)\n",
        "    return [trade]\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- You will be provided with a message by the user asking you to generate Python functions to simulate a trading strategy.\n",
        "- Your job is to generate 2 Python functions, one implementing the user's requested trading strategy and the other a trading strategy you think is better than the one provided based on your knowledge and expertise.\n",
        "- Ensure the functions are named sequentially (e.g., `trade1()`, `trade2()`, etc.).\n",
        "- Include clear comments explaining the logic behind each function.\n",
        "- Return a list of `Trade` objects from each function.\n",
        "- The output should only include the Python code. Do not include any introductions, conclusions, summaries, or additional context.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6WYxE0goBfbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_prompt(user_strategy):\n",
        "  return f\"{user_strategy} based on the user strategy, write a python code that would simulate that strategy \\\n",
        "  and another function that would be an improvement on this one based on your knowledge and expertise. Make sure each function has clear comments explaining the logic and return a list of Trade objects.\""
      ],
      "metadata": {
        "id": "7V4sa5rEGw6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Claude's function for generating the code\n",
        "def claude_trade(user_strategy):\n",
        "  client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
        "  result = client.messages.stream(\n",
        "          model=CLAUDE_MODEL,\n",
        "          max_tokens=MAX_TOKENS,\n",
        "          system=SYSTEM_PROMPT,\n",
        "          messages=[{\"role\": \"user\", \"content\": user_prompt(user_strategy)}],\n",
        "      )\n",
        "  reply = \"\"\n",
        "  with result as stream:\n",
        "      for text in stream.text_stream:\n",
        "          reply += text\n",
        "          yield reply.replace(\"```python\\n\", \"\").replace(\"```\", \"\")"
      ],
      "metadata": {
        "id": "S9Ks41g_HVkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Qwen's function for generating the code\n",
        "def qwen_trade(user_strategy):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(code_qwen)\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "      {\"role\": \"user\", \"content\": user_prompt(user_strategy)}\n",
        "  ]\n",
        "  text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "  client = InferenceClient(CODE_QWEN_URL, token=hf_token)\n",
        "  stream = client.text_generation(text, stream=True, details=True, max_new_tokens=MAX_TOKENS)\n",
        "  result = \"\"\n",
        "  for r in stream:\n",
        "      result += r.token.text\n",
        "      yield result"
      ],
      "metadata": {
        "id": "Bf2kFEJ3It3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_model(user_strategy, model):\n",
        "    if model==\"Claude\":\n",
        "        result = claude_trade(user_strategy)\n",
        "    elif model==\"CodeQwen\":\n",
        "        result = qwen_trade(user_strategy)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    for stream_so_far in result:\n",
        "        yield stream_so_far"
      ],
      "metadata": {
        "id": "U0iXxs-KJj6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Gradio interface"
      ],
      "metadata": {
        "id": "Hd_FAv7tJ23Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_choices = [\n",
        "    \"Claude\",\n",
        "    \"CodeQwen\"\n",
        "]"
      ],
      "metadata": {
        "id": "LYyIT8gPMLDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as ui:\n",
        "    gr.Markdown(\"## AI Assistant to write Python code for Trading Strategies\")\n",
        "    with gr.Row():\n",
        "        trade_strategy = gr.Textbox(\n",
        "              label=\"📄 Trading Strategy\",\n",
        "              placeholder=\"Write your trading strategy here...\",\n",
        "              lines=15,\n",
        "              elem_id=\"trading_strategy\"\n",
        "          )\n",
        "        python = gr.Textbox(\n",
        "              label=\"📊 Generated Python Code\",\n",
        "              placeholder=\"Python code with one extra trading strategy will appear here...\",\n",
        "              lines=15,\n",
        "              interactive=False,\n",
        "              elem_id=\"python_code\"\n",
        "          )\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(choices=model_choices, label=\"🤖  Select AI Model\", value=\"Claude\")\n",
        "        generate_code = gr.Button(\"Generate Code\")\n",
        "    generate_code.click(choose_model, inputs=[trade_strategy, model], outputs=[python])\n"
      ],
      "metadata": {
        "id": "LzzZOVDUJt8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ui.launch()"
      ],
      "metadata": {
        "id": "N052hL2cKRnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}